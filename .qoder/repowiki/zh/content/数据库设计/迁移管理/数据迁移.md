# 数据迁移

<cite>
**本文档引用的文件**   
- [reset_railway_db.sql](file://server/db/migrations/reset_railway_db.sql)
- [run_create_mapping_config.js](file://server/scripts/run_create_mapping_config.js)
- [run_file_id_migration.js](file://server/scripts/run_file_id_migration.js)
- [index.js](file://server/db/index.js)
- [init-db.js](file://server/scripts/init-db.js)
- [create_mapping_config.sql](file://server/db/migrations/create_mapping_config.sql)
- [add-file-id.sql](file://server/db/migrations/add-file-id.sql)
- [schema.sql](file://server/db/schema.sql)
- [init-all.sql](file://server/db/init-all.sql)
- [post-deploy.js](file://server/scripts/post-deploy.js)
</cite>

## 目录
1. [引言](#引言)
2. [数据库重置机制](#数据库重置机制)
3. [数据迁移脚本工作机制](#数据迁移脚本工作机制)
4. [数据库连接与异步处理](#数据库连接与异步处理)
5. [脚本执行方式与日志输出](#脚本执行方式与日志输出)
6. [迁移执行顺序依赖](#迁移执行顺序依赖)
7. [数据一致性校验](#数据一致性校验)
8. [生产环境最佳实践](#生产环境最佳实践)
9. [结论](#结论)

## 引言
本文档详细阐述TwinSight项目中的数据迁移机制，聚焦于现有数据的转换、初始化与迁移执行流程。文档深入分析关键迁移脚本的作用与风险控制要点，包括用于重置Railway部署环境数据库状态的`reset_railway_db.sql`脚本，以及用于初始化映射配置和执行数据填充的JavaScript迁移脚本。文档还解释了这些脚本如何利用数据库连接池进行异步批量处理，并提供了生产环境执行数据迁移的最佳实践指南。

## 数据库重置机制

`reset_railway_db.sql`脚本是用于重置Railway部署环境下数据库状态的关键工具，主要用于环境初始化或测试数据清理。该脚本通过一系列DROP TABLE语句按依赖顺序反向删除所有表，确保外键约束不会导致删除失败。

脚本首先删除所有数据表，包括`kb_documents`、`knowledge_bases`、`document_exif`、`documents`、`mapping_configs`等，然后删除`update_updated_at_column`函数。脚本明确警告此操作会删除现有数据，要求在执行前先进行备份。

该脚本的风险控制要点在于其执行顺序和数据丢失风险。由于它会完全清除数据库，因此必须在执行前确保有完整的数据备份。此外，脚本设计为与`init-all.sql`配合使用，执行完重置后需立即运行`init-all.sql`来重建完整的数据库结构。

**Section sources**
- [reset_railway_db.sql](file://server/db/migrations/reset_railway_db.sql#L1-L29)

## 数据迁移脚本工作机制

### 映射配置初始化

`run_create_mapping_config.js`脚本用于初始化默认的映射配置记录，确保新部署实例具备基础的导出结构。该脚本通过读取`create_mapping_config.sql`文件内容并执行其中的SQL语句来创建`mapping_configs`表。

脚本首先建立与数据库的连接，使用环境变量配置连接参数。成功连接后，它读取SQL文件并执行创建表的语句。`mapping_configs`表包含`file_id`、`config_type`（如'asset'、'asset_spec'、'space'）、`field_name`等关键字段，并设置了适当的索引和唯一约束。

此脚本确保了系统在新部署时具备必要的映射配置基础结构，为后续的数据导出和映射功能提供支持。

**Section sources**
- [run_create_mapping_config.js](file://server/scripts/run_create_mapping_config.js#L1-L36)
- [create_mapping_config.sql](file://server/db/migrations/create_mapping_config.sql#L1-L29)

### 文件ID数据迁移

`run_file_id_migration.js`脚本负责将旧版文档记录与新的`file_id`字段进行数据填充，实现系统的平滑升级。该脚本通过执行`add-file-id.sql`迁移脚本，为多个核心数据表添加`file_id`字段。

迁移过程包括为`asset_specs`、`assets`、`spaces`和`classifications`表添加`file_id`列，并建立与`model_files`表的外键关系。同时，脚本修改了这些表的唯一约束，从单一字段唯一性变为`file_id`与业务编码的组合唯一性，如`assets_file_asset_unique`约束确保`file_id`和`asset_code`的组合唯一。

脚本在执行时使用事务控制，先执行`BEGIN`开始事务，执行所有迁移操作后执行`COMMIT`提交更改。如果过程中发生错误，则执行`ROLLBACK`回滚所有更改，确保数据库状态的一致性。

**Section sources**
- [run_file_id_migration.js](file://server/scripts/run_file_id_migration.js#L1-L53)
- [add-file-id.sql](file://server/db/migrations/add-file-id.sql#L1-L51)

## 数据库连接与异步处理

### 数据库连接池机制

`server/db/index.js`文件实现了数据库连接池的核心机制，为所有数据迁移脚本提供统一的数据库访问接口。该模块根据环境配置创建连接池，优先使用`DATABASE_URL`环境变量（适用于Railway等云服务），否则使用独立的数据库连接参数。

连接池配置包括最大连接数（20）、空闲超时时间（30000毫秒）和连接超时时间（10000毫秒）。对于Railway内部网络连接，脚本自动禁用SSL，而外部连接则启用SSL但允许自签名证书。

连接池提供了`query`、`getClient`和`closePool`三个主要接口，分别用于执行SQL查询、获取客户端连接（用于事务）和关闭连接池。`query`函数包含错误处理和性能监控，记录查询执行时间和行数。

**Section sources**
- [index.js](file://server/db/index.js#L1-L93)

### 异步批量处理

数据迁移脚本利用Node.js的异步特性进行批量数据处理。所有数据库操作都通过`async/await`语法实现非阻塞执行，确保在处理大量数据时不会阻塞主线程。

`run_file_id_migration.js`脚本展示了典型的异步处理模式：首先获取连接池中的客户端连接，然后在`try-catch-finally`块中执行迁移操作。`try`块中包含核心的迁移逻辑，`catch`块处理错误并执行事务回滚，`finally`块确保连接被正确释放和连接池关闭。

这种异步处理模式允许脚本高效地处理大量数据，同时保持良好的错误处理能力和资源管理。

**Section sources**
- [run_file_id_migration.js](file://server/scripts/run_file_id_migration.js#L26-L53)
- [index.js](file://server/db/index.js#L62-L73)

## 脚本执行方式与日志输出

### 命令行执行方式

数据迁移脚本通过Node.js命令行直接执行。例如，`run_create_mapping_config.js`可以通过`node server/scripts/run_create_mapping_config.js`命令运行。脚本使用ES模块语法（import/export），因此需要Node.js支持ES模块的版本。

脚本依赖环境变量进行数据库连接配置，主要使用`DB_HOST`、`DB_PORT`、`DB_USER`、`DB_PASSWORD`和`DB_NAME`等变量。对于本地开发，这些变量通常定义在`.env.local`文件中。

### 日志输出与错误处理

所有迁移脚本都实现了详细的日志输出机制，使用表情符号和颜色编码（通过控制台输出）来区分不同类型的日志信息。脚本输出包括连接状态、执行进度、成功提示和错误信息。

例如，`run_create_mapping_config.js`脚本输出"📡 已连接到数据库"表示连接成功，"✅ 映射配置表创建成功"表示操作成功，"❌ 创建表失败:"后跟错误详情表示操作失败。`run_file_id_migration.js`脚本还输出SQL内容长度等调试信息。

错误处理机制完善，所有脚本都使用`try-catch`块捕获异常，并在`catch`块中输出详细的错误信息。对于事务性操作，脚本在捕获错误后执行`ROLLBACK`并调用`process.exit(1)`终止进程，确保不会留下部分完成的状态。

**Section sources**
- [run_create_mapping_config.js](file://server/scripts/run_create_mapping_config.js#L20-L32)
- [run_file_id_migration.js](file://server/scripts/run_file_id_migration.js#L29-L49)

## 迁移执行顺序依赖

数据迁移与模式迁移的执行顺序存在严格的依赖关系，必须遵循"先模式后数据"的原则。模式迁移负责创建或修改数据库的结构（表、字段、约束等），而数据迁移则在已建立的模式基础上填充或转换数据。

正确的执行顺序如下：
1. 首先执行模式迁移，如`reset_railway_db.sql`重置数据库结构
2. 然后执行`init-all.sql`或`schema.sql`创建完整的表结构
3. 接着执行特定的模式变更迁移，如添加`file_id`字段
4. 最后执行数据迁移脚本，填充初始数据或转换现有数据

这种顺序确保了在执行数据操作时，目标表和字段已经存在且结构正确。例如，`run_file_id_migration.js`必须在`model_files`表创建后才能成功执行，因为`file_id`字段需要引用该表的主键。

**Section sources**
- [init-db.js](file://server/scripts/init-db.js#L1-L40)
- [post-deploy.js](file://server/scripts/post-deploy.js#L1-L182)

## 数据一致性校验

### 迁移前后校验

数据迁移过程中的数据一致性校验至关重要。建议在迁移前后执行记录数对比，确保数据完整性。例如，在执行`add-file-id.sql`迁移前后，可以查询`assets`、`spaces`等表的记录数，验证是否一致。

关键字段非空验证也是重要的校验方法。迁移后应检查新添加的`file_id`字段是否都已正确填充，没有空值。可以通过SQL查询`SELECT COUNT(*) FROM assets WHERE file_id IS NULL`来验证。

### 约束验证

迁移脚本应验证数据库约束是否正确建立。例如，`add_mapping_config_fk.sql`脚本在添加外键约束后，执行查询验证约束是否存在。类似的验证机制可以确保数据完整性和引用完整性。

对于唯一性约束，应验证组合唯一性是否按预期工作。例如，测试插入具有相同`asset_code`但不同`file_id`的记录是否被允许，而插入具有相同`file_id`和`asset_code`的记录是否被拒绝。

**Section sources**
- [add_mapping_config_fk.sql](file://server/db/migrations/add_mapping_config_fk.sql#L1-L26)
- [add-file-id.sql](file://server/db/migrations/add-file-id.sql#L1-L51)

## 生产环境最佳实践

### 备份策略

在生产环境执行任何数据迁移前，必须执行完整的数据库备份。建议使用`pg_dump`工具创建逻辑备份，并将备份文件存储在安全的位置。对于Railway环境，可以利用其内置的备份功能。

备份应包括完整的数据库结构和数据，并在迁移前验证备份的可恢复性。建议在非高峰时段执行备份和迁移操作，以最小化对用户的影响。

### 灰度执行

对于大型生产环境，建议采用灰度执行策略。首先在预发布环境中验证迁移脚本，然后在小范围用户或非关键数据上执行，最后再推广到全部数据。可以使用数据库事务来测试迁移，执行后立即回滚，验证脚本的正确性而不影响实际数据。

### 回滚预案

每个数据迁移操作都必须有明确的回滚预案。对于简单的模式变更，回滚脚本应包含反向操作，如删除添加的字段或表。对于复杂的数据转换，可能需要从备份中恢复数据。

回滚预案应包括：
- 回滚脚本或步骤
- 预期的回滚时间
- 回滚后的验证方法
- 通知相关方的流程

所有参与迁移的团队成员都应熟悉回滚流程，并在迁移前进行演练。

**Section sources**
- [reset_railway_db.sql](file://server/db/migrations/reset_railway_db.sql#L1-L29)
- [init-all.sql](file://server/db/init-all.sql#L1-L389)

## 结论
TwinSight项目的数据迁移机制设计完善，通过SQL脚本和JavaScript脚本的结合，实现了灵活而可靠的数据转换和初始化功能。`reset_railway_db.sql`脚本提供了强大的环境重置能力，而`run_create_mapping_config.js`和`run_file_id_migration.js`脚本则确保了新部署实例的正确配置和数据的平滑升级。

这些脚本通过`server/db/index.js`提供的连接池进行高效的异步批量处理，结合详细的日志输出和错误处理机制，确保了迁移过程的可监控性和可靠性。遵循"先模式后数据"的执行顺序，并实施严格的数据一致性校验，可以最大限度地保证数据完整性。

在生产环境中执行数据迁移时，应遵循备份、灰度执行和回滚预案的最佳实践，确保系统的稳定性和数据的安全性。通过这些机制，TwinSight项目能够安全、可靠地管理其数据迁移过程，支持系统的持续演进和升级。