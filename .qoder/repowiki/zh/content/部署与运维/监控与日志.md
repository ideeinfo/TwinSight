# 监控与日志

<cite>
**本文档引用的文件**   
- [nginx.conf](file://docker/nginx.conf#L1-L240)
- [api.js](file://server/routes/api.js#L1-L603)
- [error-handler.js](file://server/middleware/error-handler.js#L1-L115)
- [database.js](file://server/config/database.js#L1-L74)
- [entrypoint.sh](file://docker/entrypoint.sh#L1-L36)
- [test-db-connection.js](file://server/scripts/test-db-connection.js#L1-L68)
- [CLOUD_DEPLOYMENT_GUIDE.md](file://CLOUD_DEPLOYMENT_GUIDE.md#L1-L740)
</cite>

## 目录
1. [日志查看方法](#日志查看方法)
2. [Nginx日志格式与分析](#nginx日志格式与分析)
3. [关键监控指标](#关键监控指标)
4. [健康检查端点](#健康检查端点)
5. [外部监控系统集成](#外部监控系统集成)
6. [常见日志错误排查](#常见日志错误排查)

## 日志查看方法

在Docker环境中，可以通过`docker logs`命令查看各个容器的运行日志。根据项目架构，主要需要监控以下容器的日志：

- **api容器**：后端API服务，包含业务逻辑和数据库交互日志
- **nginx容器**：反向代理服务，包含访问日志和错误日志
- **n8n容器**：AI工作流自动化服务，包含工作流执行日志
- **open-webui容器**：AI对话界面服务，包含Gemini API调用日志
- **nodered容器**：IoT数据流处理服务，包含传感器数据处理日志
- **postgres容器**：PostgreSQL数据库服务，包含数据库操作日志
- **influxdb容器**：时序数据库服务，包含时间序列数据写入日志

查看特定容器日志的基本命令格式为：
```bash
docker logs <container_name>
```

例如，查看API服务的实时日志：
```bash
docker logs -f twinsight-api
```

查看Nginx错误日志：
```bash
docker logs twinsight-nginx
```

对于长时间运行的服务，建议使用`-f`参数实时跟踪日志输出，或使用`--tail`参数查看最近的若干行日志：
```bash
# 查看最近100行日志
docker logs --tail 100 twinsight-api

# 实时跟踪日志
docker logs -f twinsight-api
```

**Section sources**
- [CLOUD_DEPLOYMENT_GUIDE.md](file://CLOUD_DEPLOYMENT_GUIDE.md#L394-L441)

## Nginx日志格式与分析

Nginx配置文件`docker/nginx.conf`中定义了详细的访问日志和错误日志格式，这对于系统监控和故障排查至关重要。

### 访问日志格式

在`nginx.conf`文件中，通过`log_format main`指令定义了访问日志的格式：
```
log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                '$status $body_bytes_sent "$http_referer" '
                '"$http_user_agent" "$http_x_forwarded_for"';
```

该格式包含以下字段：
- `$remote_addr`：客户端IP地址
- `$remote_user`：认证用户（如果启用了HTTP基本认证）
- `$time_local`：本地服务器时间
- `$request`：完整的请求行（方法、URI、协议）
- `$status`：HTTP响应状态码
- `$body_bytes_sent`：发送给客户端的字节数
- `$http_referer`：引用页面（来源页面）
- `$http_user_agent`：客户端用户代理（浏览器信息）
- `$http_x_forwarded_for`：X-Forwarded-For头，用于识别通过HTTP代理或负载均衡器原始IP地址

### 错误日志配置

Nginx的错误日志配置如下：
```
access_log /var/log/nginx/access.log main;
error_log /var/log/nginx/error.log warn;
```

其中，`warn`级别表示记录警告及以上级别的错误信息。错误日志主要用于诊断Nginx自身的配置错误、文件权限问题、网络连接问题等。

### 日志分析方法

通过分析Nginx访问日志，可以获取以下关键信息：

1. **请求频率分析**：统计单位时间内的请求数量，识别流量高峰
2. **错误率监控**：统计4xx和5xx状态码的比例，及时发现服务异常
3. **响应时间分析**：虽然当前配置未包含响应时间，但可以通过日志时间戳计算
4. **用户行为分析**：通过User-Agent分析客户端类型，通过Referer分析流量来源
5. **安全监控**：识别异常的请求模式，如频繁的404错误可能表示扫描行为

建议定期对Nginx日志进行分析，可以使用工具如`awk`、`grep`等进行简单的统计分析，或集成专业的日志分析系统如ELK（Elasticsearch, Logstash, Kibana）或Grafana+Loki。

**Section sources**
- [nginx.conf](file://docker/nginx.conf#L17-L23)

## 关键监控指标

为了确保系统稳定运行，需要监控以下关键指标：

### API响应时间

API响应时间是衡量系统性能的核心指标。在`server/config/database.js`文件中，数据库查询函数记录了每个查询的执行时间：

```javascript
export const query = async (text, params) => {
    const start = Date.now();
    const res = await pool.query(text, params);
    const duration = Date.now() - start;
    return res;
};
```

通过监控数据库查询的`duration`，可以识别慢查询并进行优化。同时，建议在API网关或Nginx层面监控端到端的响应时间。

### 错误率

错误率是系统健康状况的重要指标。根据`server/middleware/error-handler.js`中的错误处理逻辑，系统定义了多种错误类型：

- 400 Bad Request：客户端请求错误
- 401 Unauthorized：未授权访问
- 403 Forbidden：禁止访问
- 404 Not Found：资源不存在
- 409 Conflict：数据冲突
- 500 Internal Server Error：服务器内部错误

建议监控5xx错误率（服务器错误）和4xx错误率（客户端错误）的比率，当错误率超过预设阈值时触发告警。

### 并发连接数

并发连接数反映了系统的负载情况。在`docker/nginx.conf`中，通过以下配置优化连接处理：

```
events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

keepalive_timeout 65;
```

建议监控Nginx的活跃连接数，确保不超过`worker_connections`的限制。可以通过Nginx的`stub_status`模块或集成Prometheus进行监控。

### 数据库连接池

在`server/config/database.js`中，PostgreSQL连接池配置如下：

```javascript
const pool = new Pool({
    max: 20, // 最大连接数
    idleTimeoutMillis: 30000,
    connectionTimeoutMillis: 2000,
});
```

需要监控数据库连接池的使用情况，包括：
- 活跃连接数
- 空闲连接数
- 连接等待时间
- 连接超时次数

当连接池接近最大容量时，可能需要优化查询性能或增加连接池大小。

### 系统资源使用率

除了应用层面的指标，还需要监控容器的系统资源使用情况：
- CPU使用率
- 内存使用量
- 磁盘I/O
- 网络带宽

这些指标可以通过Docker的`stats`命令或集成监控系统获取。

**Section sources**
- [database.js](file://server/config/database.js#L10-L20)
- [error-handler.js](file://server/middleware/error-handler.js#L9-L40)
- [nginx.conf](file://docker/nginx.conf#L7-L11)

## 健康检查端点

系统提供了`/health`健康检查端点，用于监控服务的运行状态。根据`CLOUD_DEPLOYMENT_GUIDE.md`中的配置，该端点被用于Railway平台的健康检查：

```json
"deploy": {
    "healthcheckPath": "/api/health",
    "healthcheckTimeout": 60,
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 5,
    "numReplicas": 1
}
```

在`docker/nginx.conf`中，Nginx配置将`/health`请求代理到后端API：

```
location /health {
    proxy_pass http://api/api/health;
    proxy_set_header Host $host;
}
```

健康检查端点的主要功能包括：
1. **服务存活检测**：确认API服务是否正常运行
2. **依赖服务检查**：检查数据库等关键依赖是否可用
3. **自动恢复**：当健康检查失败时，平台可以自动重启服务实例
4. **负载均衡**：在多实例部署中，负载均衡器可以根据健康检查结果路由流量

建议定期测试健康检查端点：
```bash
curl -I http://localhost/health
```

正常情况下应返回HTTP 200状态码。如果健康检查持续失败，需要检查API服务和数据库连接状态。

**Section sources**
- [CLOUD_DEPLOYMENT_GUIDE.md](file://CLOUD_DEPLOYMENT_GUIDE.md#L313-L317)
- [nginx.conf](file://docker/nginx.conf#L234-L237)

## 外部监控系统集成

为了实现全面的系统监控，建议集成外部监控系统。根据项目架构，可以采用以下集成方案：

### Grafana + InfluxDB 监控方案

项目架构中包含了Grafana和InfluxDB组件，可以构建完整的监控解决方案：

- **InfluxDB**：作为时序数据库，存储监控指标数据
- **Grafana**：作为可视化仪表盘，展示监控数据

在`CLOUD_DEPLOYMENT_GUIDE.md`中提到了Grafana的部署：
> **Grafana** | Grafana | 3000 | ⚠️ | 数据可视化 |

通过Node-RED将IoT设备数据写入InfluxDB，然后在Grafana中创建仪表盘展示关键指标。

### 日志收集与分析

建议集成集中式日志管理系统，如：

1. **ELK Stack**（Elasticsearch, Logstash, Kibana）
   - 使用Filebeat收集各容器日志
   - 通过Logstash进行日志解析和过滤
   - 在Kibana中进行可视化分析

2. **Grafana Loki**
   - 轻量级日志聚合系统
   - 与Grafana无缝集成
   - 支持高效的日志查询

### 告警系统

基于监控数据设置告警规则，当指标超过阈值时通知相关人员。告警方式包括：
- 邮件通知
- 短信通知
- 即时通讯工具（如钉钉、企业微信）
- 电话告警

在`CLOUD_DEPLOYMENT_GUIDE.md`的部署检查清单中提到了监控告警配置：
> - [ ] 监控告警已配置

### 自定义监控脚本

项目中包含了一些监控相关的脚本，如`server/scripts/test-db-connection.js`，可以作为自定义监控的基础：

```javascript
async function testConnection() {
    try {
        const result = await pool.query('SELECT NOW() as now, current_database() as db');
        console.log('✅ 数据库连接成功！');
    } catch (error) {
        console.error('\n❌ 数据库连接失败:', error.message);
    }
}
```

可以扩展此类脚本，定期检查关键服务的可用性，并将结果发送到监控系统。

**Section sources**
- [CLOUD_DEPLOYMENT_GUIDE.md](file://CLOUD_DEPLOYMENT_GUIDE.md#L41-L42)
- [test-db-connection.js](file://server/scripts/test-db-connection.js#L17-L68)

## 常见日志错误排查

根据系统架构和日志配置，以下是常见错误的排查方案：

### 数据库连接失败

当出现数据库连接失败时，日志中通常会显示相关错误信息。

**排查步骤：**
1. 检查`docker logs`中API容器的日志，寻找数据库连接错误
2. 确认数据库服务是否正常运行：`docker ps | grep postgres`
3. 检查环境变量配置，确保`DATABASE_URL`或数据库连接参数正确
4. 使用`server/scripts/test-db-connection.js`脚本测试数据库连接
5. 检查网络连接，确保API容器可以访问数据库容器

在`docker/entrypoint.sh`中，容器启动时会自动执行数据库初始化：
```bash
# 使用 Node.js 执行数据库初始化脚本
node scripts/post-deploy.js
```

如果此步骤失败，说明数据库连接存在问题。

### 认证错误

认证错误通常表现为401 Unauthorized或403 Forbidden状态码。

**排查步骤：**
1. 检查Nginx访问日志中的状态码和请求路径
2. 查看API日志中的详细错误信息
3. 确认认证令牌是否正确生成和传递
4. 检查`server/middleware/auth.js`中的认证逻辑
5. 验证用户权限配置是否正确

在`error-handler.js`中定义了认证相关的错误处理：
```javascript
static unauthorized(message = '未授权') {
    return new ApiError(401, message);
}

static forbidden(message = '禁止访问') {
    return new ApiError(403, message);
}
```

### 文件上传超限

文件上传超限错误通常由Nginx的`client_max_body_size`配置引起。

**排查步骤：**
1. 检查Nginx错误日志，寻找"413 Request Entity Too Large"错误
2. 确认`docker/nginx.conf`中的上传限制配置：
   ```
   client_max_body_size 500M;
   ```
3. 根据业务需求调整上传限制大小
4. 如果需要支持大文件上传，考虑实现分片上传功能
5. 检查服务器磁盘空间，确保有足够的存储空间

### API响应超时

API响应超时可能是由多种原因引起的。

**排查步骤：**
1. 检查Nginx访问日志中的响应时间
2. 查看API日志，识别慢查询或复杂操作
3. 检查数据库性能，优化慢查询
4. 确认系统资源使用情况，避免CPU或内存瓶颈
5. 调整Nginx的代理超时设置：
   ```
   proxy_read_timeout 86400s;
   proxy_send_timeout 86400s;
   ```

### n8n工作流执行失败

n8n工作流执行失败会影响AI分析功能。

**排查步骤：**
1. 查看n8n容器日志：`docker logs twinsight-n8n`
2. 检查工作流配置，确保所有节点配置正确
3. 验证API密钥（如Gemini API Key）是否有效
4. 检查数据库连接配置
5. 在n8n界面中查看具体的工作流执行错误信息

**Section sources**
- [entrypoint.sh](file://docker/entrypoint.sh#L15-L28)
- [error-handler.js](file://server/middleware/error-handler.js#L21-L26)
- [nginx.conf](file://docker/nginx.conf#L42)
- [CLOUD_DEPLOYMENT_GUIDE.md](file://CLOUD_DEPLOYMENT_GUIDE.md#L144-L163)