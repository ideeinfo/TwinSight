/**
 * ç³»ç»Ÿé…ç½® API è·¯ç”±
 * ç”¨äºç®¡ç† LLM ç­‰ç³»ç»Ÿçº§é…ç½®
 */
import { Router } from 'express';
import pool from '../../db/index.js';
import { getConfig, setConfig, getAllConfigs, clearConfigCache } from '../../services/config-service.js';

const router = Router();

// é¢„ç½® LLM æä¾›å•†é…ç½®
const LLM_PROVIDERS = {
    gemini: {
        name: 'Google Gemini',
        baseUrl: 'https://generativelanguage.googleapis.com/v1beta/openai/',
        modelsEndpoint: '/models'
    },
    qwen: {
        name: 'é€šä¹‰åƒé—® (Qwen)',
        baseUrl: 'https://dashscope.aliyuncs.com/compatible-mode/v1',
        modelsEndpoint: '/models'
    },
    deepseek: {
        name: 'DeepSeek',
        baseUrl: 'https://api.deepseek.com/v1',
        modelsEndpoint: '/models'
    }
};

/**
 * GET /api/v1/system-config/llm/providers
 * è·å–é¢„ç½®çš„ LLM æä¾›å•†åˆ—è¡¨
 */
router.get('/llm/providers', (req, res) => {
    const providers = Object.entries(LLM_PROVIDERS).map(([key, value]) => ({
        id: key,
        name: value.name,
        baseUrl: value.baseUrl
    }));
    res.json({ success: true, data: providers });
});

/**
 * GET /api/v1/system-config/llm
 * è·å– LLM é…ç½®ï¼ˆAPI Key åªè¿”å›æ˜¯å¦å·²é…ç½®ï¼‰
 */
router.get('/llm', async (req, res) => {
    try {
        const provider = await getConfig('LLM_PROVIDER', 'gemini');
        const apiKey = await getConfig('LLM_API_KEY', '');
        const baseUrl = await getConfig('LLM_BASE_URL', LLM_PROVIDERS.gemini.baseUrl);
        const model = await getConfig('LLM_MODEL', '');

        res.json({
            success: true,
            data: {
                provider,
                hasApiKey: !!apiKey,
                apiKeyMasked: apiKey ? 'â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢' + apiKey.slice(-4) : '',
                baseUrl,
                model
            }
        });
    } catch (error) {
        console.error('è·å– LLM é…ç½®å¤±è´¥:', error);
        res.status(500).json({ success: false, error: 'è·å–é…ç½®å¤±è´¥' });
    }
});

/**
 * PUT /api/v1/system-config/llm
 * æ›´æ–° LLM é…ç½®
 */
router.put('/llm', async (req, res) => {
    try {
        const { provider, apiKey, baseUrl, model } = req.body;

        if (provider) {
            await setConfig('LLM_PROVIDER', provider, 'LLM æœåŠ¡æä¾›å•†');
        }
        if (apiKey !== undefined) {
            await setConfig('LLM_API_KEY', apiKey, 'LLM API Key');
        }
        if (baseUrl) {
            await setConfig('LLM_BASE_URL', baseUrl, 'OpenAI å…¼å®¹ API åŸºç¡€ URL');
        }
        if (model !== undefined) {
            await setConfig('LLM_MODEL', model, 'é€‰æ‹©çš„æ¨¡å‹åç§°');
        }

        // æ¸…é™¤ç¼“å­˜
        clearConfigCache();

        res.json({ success: true, message: 'LLM é…ç½®å·²æ›´æ–°' });
    } catch (error) {
        console.error('æ›´æ–° LLM é…ç½®å¤±è´¥:', error);
        res.status(500).json({ success: false, error: 'æ›´æ–°é…ç½®å¤±è´¥' });
    }
});

/**
 * POST /api/v1/system-config/llm/models
 * è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
 */
router.post('/llm/models', async (req, res) => {
    try {
        const { provider, apiKey, baseUrl } = req.body;

        if (!apiKey) {
            return res.status(400).json({ success: false, error: 'è¯·æä¾› API Key' });
        }

        const effectiveBaseUrl = baseUrl || (LLM_PROVIDERS[provider]?.baseUrl);
        if (!effectiveBaseUrl) {
            return res.status(400).json({ success: false, error: 'æ— æ•ˆçš„æä¾›å•†æˆ– URL' });
        }

        // æ„å»ºæ¨¡å‹åˆ—è¡¨ API URL
        const modelsUrl = effectiveBaseUrl.replace(/\/$/, '') + '/models';

        console.log(`ğŸ“¡ è·å–æ¨¡å‹åˆ—è¡¨: ${modelsUrl}`);

        const response = await fetch(modelsUrl, {
            method: 'GET',
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json'
            }
        });

        if (!response.ok) {
            const errorText = await response.text();
            console.error('è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥:', response.status, errorText);
            return res.status(response.status).json({
                success: false,
                error: `è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: ${response.status}`
            });
        }

        const result = await response.json();

        // è§£ææ¨¡å‹åˆ—è¡¨ï¼ˆOpenAI æ ¼å¼ï¼‰
        let models = [];
        if (result.data && Array.isArray(result.data)) {
            models = result.data.map(m => ({
                id: m.id,
                name: m.id,
                owned_by: m.owned_by || provider
            }));
        } else if (result.models && Array.isArray(result.models)) {
            // Gemini æ ¼å¼
            models = result.models.map(m => ({
                id: m.name || m.id,
                name: m.displayName || m.name || m.id,
                owned_by: 'google'
            }));
        }

        // è¿‡æ»¤å‡ºé€‚åˆèŠå¤©çš„æ¨¡å‹
        const chatModels = models.filter(m => {
            const id = m.id.toLowerCase();
            // æ’é™¤ embeddingã€vision-only ç­‰éèŠå¤©æ¨¡å‹
            return !id.includes('embedding') &&
                !id.includes('whisper') &&
                !id.includes('tts') &&
                !id.includes('dall-e');
        });

        res.json({ success: true, data: chatModels });
    } catch (error) {
        console.error('è·å–æ¨¡å‹åˆ—è¡¨å¼‚å¸¸:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});

/**
 * POST /api/v1/system-config/llm/test
 * æµ‹è¯• LLM è¿æ¥
 */
router.post('/llm/test', async (req, res) => {
    try {
        const { provider, apiKey, baseUrl, model } = req.body;

        if (!apiKey || !model) {
            return res.status(400).json({ success: false, error: 'è¯·æä¾› API Key å’Œæ¨¡å‹' });
        }

        const effectiveBaseUrl = baseUrl || (LLM_PROVIDERS[provider]?.baseUrl);
        if (!effectiveBaseUrl) {
            return res.status(400).json({ success: false, error: 'æ— æ•ˆçš„æä¾›å•†æˆ– URL' });
        }

        // æ„å»ºèŠå¤© API URL
        const chatUrl = effectiveBaseUrl.replace(/\/$/, '') + '/chat/completions';

        console.log(`ğŸ§ª æµ‹è¯• LLM è¿æ¥: ${chatUrl}, æ¨¡å‹: ${model}`);

        const response = await fetch(chatUrl, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${apiKey}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: model,
                messages: [{ role: 'user', content: 'Hello' }],
                max_tokens: 10
            })
        });

        if (!response.ok) {
            const errorText = await response.text();
            console.error('LLM è¿æ¥æµ‹è¯•å¤±è´¥:', response.status, errorText);
            return res.status(response.status).json({
                success: false,
                error: `è¿æ¥æµ‹è¯•å¤±è´¥: ${response.status}`
            });
        }

        const result = await response.json();
        console.log('âœ… LLM è¿æ¥æµ‹è¯•æˆåŠŸ');

        res.json({
            success: true,
            message: 'è¿æ¥æµ‹è¯•æˆåŠŸ',
            response: result.choices?.[0]?.message?.content || '(æ— å“åº”å†…å®¹)'
        });
    } catch (error) {
        console.error('LLM è¿æ¥æµ‹è¯•å¼‚å¸¸:', error);
        res.status(500).json({ success: false, error: error.message });
    }
});

export default router;
